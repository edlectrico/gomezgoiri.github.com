<!DOCTYPE html>
<html>
  <head>
    <title>Semantic Tuple Spaces for Constrained Devices: A Web-compliant Vision</title>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    <base href="https://dl.dropboxusercontent.com/u/9804351/">
    <!--<base href="http://localhost:8000/">-->
    <link rel="stylesheet" type="text/css" href="own-style.css" media="screen" />
  </head>
  <body>
    <textarea id="source">

class: center, frontpage

.frontcontent-outer[
 .frontcontent-inner[

# Semantic Tuple Spaces for Constrained Devices: A Web-compliant Vision
## Aitor Gómez Goiri .breakline[ [gomezgoiri.net](http://gomezgoiri.net)]

<!--Internet unit, [DeustoTech](http://www.deustotech.deusto.es/)
.breakline[ [www.morelab.deusto.es](http://www.morelab.deusto.es) ]-->

.date[June 16, 2014]

  ]
]
???

President of the panel, members of the panel.

Ladies and gentlemen.

Good morning.

I will start the exposition and defense of my PhD thesis.

---

class: center, middle

# Introduction

---

# Background
.subtitle[
## Introduction
]

<img alt="And god said: let's make Internet" src="img/transpas/internet01.png" style="width: 90%; display: block; margin-top: 2em; margin-left: auto; margin-right: auto">

???

In the beginning researchers created the Internet.

Internet composed by few computers.

---

# Background
.subtitle[
## Introduction
]
<img alt="Internet popularizes" src="img/transpas/internet02.png" style="width: 100%; display: block;">

???

Then, the popularity of the Internet increased and connecting computers became easier and cheaper.

Consequently, more and more computers got connected.

---

# Background
.subtitle[
## Introduction
]
<img alt="Wireless comes to the Internet" src="img/transpas/internet03.png" style="width: 100%; display: block;">

???

Thanks to wireless technologies, devices started accessing to the Internet without having to be physically connected to a network.

---

# Background
.subtitle[
## Introduction
]
<img alt="Mobile computing appears" src="img/transpas/internet04.png" style="width: 100%; display: block;">

???

So the __mobile computing__ appeared.

---

# Background
.subtitle[
## Introduction
]
<img alt="The Internet of Things appears" src="img/transpas/internet05.png" style="width: 100%; display: block;">

???

Nowadays, __not only__ a wider range of smartphones, but also everyday objects like cars or washing machines connect to the Internet to exchange information.

This is what __is know as__ the Internet of Things (IoT).

---

# Background: UbiComp
.subtitle[
## Introduction
]

<img alt="Guy reading the news while his home works on his behalf" src="img/transpas/ubicomp01.png" style="width: 100%; display: block;">

???

Both the IoT and the mobile computing have __contributed to Ubicomp__.

UbiComp is a term __coined__ by Mark Weiser (in the early nineties).

It describes environments where devices imperceptibly work on our behalf.

---

# Background: UbiComp
.subtitle[
## Introduction
]

<img alt="Devices work together" src="img/transpas/ubicomp02.png" style="width: 100%; display: block;">

???

But, in Mark's words, UbiComp's real power "comes not from any one of these devices, it emerges from the __interaction of all__ of them".

This interaction brings __challenges__ to UbiComp.

In this thesis I've  focused on two of them.

---

# UbiComp, challenge 1: dynamism
.subtitle[
## Introduction
]

<img alt="Guy reading the news while his home works on his behalf" src="img/transpas/ubicomp01.png" style="width: 100%; display: block;">

???

First, we have the dynamism.

This dynamism has its effects both in the short and the long term.

Since most devices have a mobile nature, they can come and go frequently in the short term.

---

# UbiComp, challenge 1: dynamism
.subtitle[
## Introduction
]

<img alt="The umbrella goes out" src="img/transpas/ubicomp03.png" style="width: 100%; display: block;">

???

For instance, in the figure we can see that the umbrella which was in the stand few moments ago, is now being used outside the house.

---

# UbiComp, challenge 1: dynamism
.subtitle[
## Introduction
]

<img alt="Guy reading the news while his home works on his behalf" src="img/transpas/ubicomp01.png" style="width: 100%; display: block;">

???

The environment also changes in the long term whenever an element is definitively replaced.

---

# UbiComp, challenge 1: dynamism
.subtitle[
## Introduction
]

<img alt="The clock is renewed" src="img/transpas/ubicomp04.png" style="width: 100%; display: block;">

???

For instance, we could replace the smart clock with a newer version.

---

# UbiComp, challenge 1: proposed solution
.subtitle[
## Introduction
]

<img alt="Space based computing: rd, in and out primitives" src="img/transpas/space-based.png" style="width: 80%; display: block; margin-top: 2em; margin-left: auto; margin-right: auto">

???

Space-based computing (or Tuple Spaces) faces this dynamism successfully.

Tuple Spaces is a paradigm where nodes coordinate with each other by writing and reading structured pieces of information (i.e., tuples) in a shared space.

This paradigm can be uncoupled in space and time.

__Space uncoupling__ is achieved because the nodes don't need to know each other beforehand to communicate.
That is, TS' primitives do not care about addresses and references, they just care about the content being shared.

__Time uncoupling__ is achieved because two nodes communicating with each other do not need to coexist at the same time.

<!-- TODO ¿Hacer 2 transpas aclaratorias? 1. Temporal diagrama secuencia y 2. mostrando primitivas para lo de referencia -->

---

# UbiComp, challenge 2: heterogeneity
.subtitle[
## Introduction
]

<img alt="Dude, what are you talking about?" src="img/transpas/interoperability01.png" style="width: 100%; display: block;">

???

The second challenge UbiComp has to face is that both the devices and the applications build upon them are heterogeneous.

This means that the interoperability is a key property for these environments.

---

# UbiComp, challenge 2: heterogeneity
.subtitle[
## Introduction
]

The [IEEE](http://ieeexplore.ieee.org/servlet/opac?punumber=2238) defines __interoperability__ as

 > The ability of two or more systems or components to __exchange__ information
 > and to __use__ the information that has been exchanged.

---

# UbiComp, challenge 2: heterogeneity
.subtitle[
## Introduction
]

The [IEEE](http://ieeexplore.ieee.org/servlet/opac?punumber=2238) defines __interoperability__ as

> .weak[The ability of two or more systems or components to _exchange_ information
> and to __use__ the information that has been exchanged.]

???

So, let's first talk about the second problem: how to use (or reuse) information.

---

# UbiComp, challenge 2a: use info
.subtitle[
## Introduction
]

<img alt="The robot does not understand chinese or japanese" src="img/transpas/interoperability02.png" style="width: 100%; display: block;">

???

We can identify two levels to allow this __use__:

 1. The  __syntactic__ level cares about  the format of the data (i.e. its syntax and encoding)
    * For instance, if the robot does not undestand chinese characters, the information the mobile phone provides will be useless.

 1. The __semantic__ level gives a precise meaning to the info
    * _"understandable by any other application that was not initially developed for this purpose"_ <!-- TODO cite -->
    * Following the example, this character may mean different things depending on the context (and it does actually).
    * TODO Preguntar a primez cual era el caracter conflictivo!
     * Funnily enough, I translated something to chinese for this presentation using an automatic tool.
     * When my co-supervisor asked about the meaning to a chinese colleague, it was confused because the meaning was either "X or X".

---


# UbiComp, challenge 2a: proposed solution
.subtitle[
## Introduction
]

<img alt="The robot does understand terms" src="img/transpas/interoperability03.png" style="width: 100%; display: block;">

???

To achieve both levels, I propose to use __Semantic Web__ standards and tools.

 > .weak[The __vision__ of the Semantic Web is to extend principles of the Web from documents to data.
 > Data should be accessed using the general Web architecture using, e.g., URI-s;
 > data should be __related to one another__ just as documents (or portions of documents) are already.
 > This also means creation of a common framework that allows data
 > to be __shared and reused__ across application, enterprise, and community boundaries,
 > to be __processed automatically__ by tools as well as manually,
 > including revealing possible __new relationships__ among pieces of data.]

---

# UbiComp, challenge 2b:  exchange info
.subtitle[
## Introduction
]

The [IEEE](http://ieeexplore.ieee.org/servlet/opac?punumber=2238)  defines _interoperability_ as

 > .weak[The ability of two or more systems or components to __exchange__ information
 > and to _use_ the information that has been exchanged.]


???

The other aspect which affect the interoperability is __how to exchange information__.

To interoperate, it is better to adopt a __widely accepted__ communication mechanism. <!-- mechanism/protocols -->
This is called interop __ab-initio__.

And what's more accepted today than...

---

background-image: url(img/the_web.svg)

.center[
<h2 style="margin-top:5em;">the Web!</h2>]

???

...the web?

Even this presentation is part of the web!

http://rawgit.com/gomezgoiri/gomezgoiri.github.com/master/slides/thesis/index.html

---

# Why the Web?
.subtitle[
## Introduction > UbiComp, challenge 2b:  exchange info
]
<img alt="The web is widely accepted" src="img/transpas/web_accepted01.png" style="width: 100%;" />

???

The web is massively accepted <!--by humans. (this is not a real reason) -->
 * By humans
 * But also, by machines: a lot of applications expose their capabilities using HTTP APIs

__REST__ architectural style comprises the design principles of _the modern web_

---

# Why the Web?
.subtitle[
## Introduction > UbiComp, challenge 2b:  exchange info
]
<img alt="The web is widely accepted" src="img/transpas/web_accepted02.png" style="width: 100%;" />

???

It achieves the following properties  (see Fielding's thesis)

* Scalability
* Simplicity
* Portability
* etc.

Note that most of these properties are particularly useful for limited devices.

---

# UbiComp, challenge 2b:  exchange info
.subtitle[
## Introduction
]

<img alt="The web of Things" src="img/transpas/wot.png" style="width: 100%; display: block;">

???

As a consequence, the web has been widely applied to IoT, bringing what people has called the __Web of Things__ (WoT).

<!-- Transpa backup: WoT challenges: push approach, subscription mechanisms... -->

In the WoT, everyday things expose their capabilities through web standards.
This way, they are first-class web citizens and can seamlessly work with other web apps.

This goes hand in hand with my interest in having devices which are not mere clients, but also active data providers.

---

# Summary: Solutions for UbiComp challenges
.subtitle[
## Introduction
]
<img alt="The web of Things" src="img/transpas/ubicomp_solutions.png" style="width: 100%; display: block;">

---

class: center, middle

# Motivation

---

# State-of-the-art
.subtitle[
## Motivation
]

<!-- TODO Delimit the scope in this section or in the next one? -->

<img alt="Scope of the dissertation" src="img/transpas/venn_background.png" style="width: 100%;" />

???

<!-- Aprovecho esta ptranspa para hacer una pasada superficial al estado del arte -->

After analyzing these research areas in the UbiComp domain I saw that...

Space-based computing

 * has often been applied to UbiComp
 * and it has also been used with Semantics (I focus on Triple Space Computing paradigm or TSC), <!-- Necesario porque luego lo nombro en la hipotesis -->
 * but usually centrallizing the space on powerful devices.

This is also common in most of the systems which use the Semantic Web in UbiComp.

---

# Common design: delegate semantic provision
.subtitle[
## Motivation
]
<img alt="XXX" src="img/transpas/centralized_provision01.png" class="center" style="width:100%;"/>

???

So, one popular design solution when working with limited devices is to centralize all the knowledge in a more powerful machine (or machines).
For sake of clarity, let's assume that there is just one machine.

This way, the devices periodically send their information to this machine,
and it stores all the information.

---

# Common design: delegate semantic provision
.subtitle[
## Motivation
]
<img alt="XXX" src="img/transpas/centralized_provision02.png" class="center" style="width:100%;"/>

???

Whenever a limited device needs to query for something, it has to ask to this machine.

---

# Common design: delegate semantic provision
.subtitle[
## Motivation
]
<img alt="XXX" src="img/transpas/centralized_provision03.png" class="center" style="width:100%;"/>

???

The reasons to do this are mainly two:

 1. semantic processing can add too much overhead to limited devices
 2. it is hard to ensure the information availability with unsteady (too dynamic) devices

However,

 1. Availability is not always a requirement. In fact, the unavailability, "represents" the mobile nature of the environment/space.
 1. Current embedded and mobile devices are notably more powerful than 5 years ago

And, now, let me do a brief parenthesis to talk about this...

---

# "Short" or "limited" are relative adjectives <!-- IoT? Energy-aware? -->
.subtitle[
## Motivation
]
<img alt="XXX" src="img/transpas/dunk-portrait-2006.jpg" class="center" style="width: 20em;"/>
<!-- Explain: which devices, results for semantic web testings, the evolution experienced since I first started working in this -->

???

The player in the center is Nate Robinson who, compared to any of the remaining NBA players will be considered small.
However, he is about 4 cm taller than me, so I wouldn't consider him small.

Similarly, my dissertation has focused on the limited devices needs and, still, what I propose might not be appropriate for several current limited platforms.

So, what does "limited" mean for me?
In short, I talk about any mobile or embedded device able to manage semantic annotations.
Anyhow, I propose several adaptations in my model for more restricted ones.
Really limited ones should use a Gateway, and this gateway would be part of my solution.

Personally, I have tested the feasibility of using the semantic web in several limited platforms.
Later on, I will present some of these results.

---

# Delegation of semantic provision: Problem 1
.subtitle[
## Motivation
]

<img alt="XXX" src="img/transpas/centralized_provision04.png" class="center" style="width:100%;"/>

???

So, after this parenthesis, let's return to the delegation of semantic provision and management from limited to more powerful devices.

This design has two problems.

First, when devices rely on others to provide information, it is not guaranteed
that the information accessed will accurately represent the last information
available in the data providers.

In the example, we see a limited device (e.g, a sensor) with a version of its contents created at _t3_.

---

# Delegation of semantic provision: Problem 1
.subtitle[
## Motivation
]

<img alt="XXX" src="img/transpas/centralized_provision05.png" class="center" style="width:100%;"/>

???

It sends its contents to a server.

---

# Delegation of semantic provision: Problem 1
.subtitle[
## Motivation
]

<img alt="XXX" src="img/transpas/centralized_provision06.png" class="center" style="width:100%;"/>

???

This server stores this version.

---

# Delegation of semantic provision: Problem 1
.subtitle[
## Motivation
]

<img alt="XXX" src="img/transpas/centralized_provision07.png" class="center" style="width:100%;"/>

???

Afterwards, the sensor generates a new version with new measures at t6.

---

# Delegation of semantic provision: Problem 1
.subtitle[
## Motivation
]

<img alt="XXX" src="img/transpas/centralized_provision08.png" class="center" style="width:100%;"/>

???

It is obvious that if other device now asked for the content provided by this sensor to the server...

---

# Delegation of semantic provision: Problem 1
.subtitle[
## Motivation
]

<img alt="XXX" src="img/transpas/centralized_provision09.png" class="center" style="width:100%;"/>

???

...it will get the outdated version.

---

# Delegation of semantic provision: Problem 2
.subtitle[
## Motivation
]

<img alt="XXX" src="img/transpas/centralized_provision10.png" class="center" style="width:100%;"/>

???

The second problem happens because once devices rely on intermediaries,
these intermediaries must be available at all time.
Otherwise, the devices would not be able to talk to each other.

Note that,

 * Having dedicated servers is costly and hard to manage in simple scenarios
 * Externalizing these servers, makes you system dependant on third-parties.

And this happens way too frequently on the Internet.

---

# Delegation of semantic provision: Problem 2
.subtitle[
## Motivation
]
<img alt="XXX" src="img/transpas/navaztag.png" class="center" style="width:100%;"p/>

???

For example, the Navastag was an IoT which completely depent on an external service.
The company of this internet-connected bunny dissapeared and they did not maintain the servers.
<!-- They released a poorly documented code. -->
As a consequence, nowadays the Navastag is pretty much an expensive decoration.


So, with these considerations in mind, I made myself a question:
<!-- research question => PhD opportunity -->

 * Can these devices get __more involved__ in the management of the space?
   Not only as mere clients.

---

class: center, middle

# Hyphothesis

???

To sum up these interests, I made the following hypothesis.

---

class: middle

 > The alignment of the TSC paradigm with the web's principles together with the
 > consideration of its energy and computational impact, leads to UbiComp
 > environments where heterogeneous devices communicate autonomously in an uncoupled
 > and interoperable fashion.

---

class: middle

.weak[
 > The __alignment of the TSC paradigm with the web's principles__ together with the
 > consideration of its energy and computational impact, leads to UbiComp
 > environments where heterogeneous devices communicate autonomously in an uncoupled
 > and interoperable fashion.
 ]

---

class: middle

.weak[
 > The alignment of the TSC paradigm with the web's principles together with the
 > consideration of its __energy and computational impact__, leads to UbiComp
 > environments where heterogeneous devices communicate __autonomously__ in a __uncoupled
 > and interoperable__ fashion.
]

---

# Goals

 1. Space model
 2. Search architecture
 3. Actuation mechanism

[ ICONS? ]

???

1. Propose a new space model which merges the benefits from Space-based computing and the web.
1. An energy-aware search for this new model.
1. An actuation mechanism.

In my dissertation, and in this presentation, I've focused on the second aspect.

Consequently, I will restrict myself to a brief comment on the first and third points.

---

class: center, middle

# Space model

.citations[

* Aitor Gómez-Goiri, Pablo Orduña, Javier Diego, Diego López-de-Ipiña.
Otsopack: Lightweight semantic framework for interoperable ambient intelligence applications.
[Computers in Human Behavior](http://www.journals.elsevier.com/computers-in-human-behavior/),
[Vol. 30](http://www.sciencedirect.com/science/journal/07475632/30/supp/C), Pages [460-467](http://www.sciencedirect.com/science/article/pii/S0747563213002148), January 2014.
* Aitor Gómez-Goiri, Pablo Orduña and Diego López-De-Ipiña.
RESTful Triple Spaces of Things.
Third International Workshop on the Web of Things (WoT 2012). Newcastle, UK, June 2012.
* Aitor Gómez-Goiri, Pablo Orduña, David Ausín, Mikel Emaldi and Diego López-de-Ipiña.
Collaboration of Sensors and Actuators through Triple Spaces.
In [IEEE Sensors 2011](http://ieee-sensors2011.org/), pages 651-654. Limerick, Ireland, October 2011.
* Aitor Gómez-Goiri, Diego López-de-Ipiña.
On the complementarity of Triple Spaces and the Web of Things.
In Proceedings of the Second International Workshop on Web of Things, WoT'11, pages 12:1–12:6.

]

---

# Space model

<img alt="Proposed dual model" src="img/new_model.svg" style="width: 100%;" />

Analysis:

 * Networking properties
 * Coordination properties
 * Is it for limited devices?

???

After several attempts, I came up with the __dual model__ shown in the figure.

It is composed by:

 * Coordination space
  * Pretty much a classical semantic space
  * It is enhanced by the information provided by autonomous devices (or asteroids) which are part of the
 * Outer space
  * __Enriched view__
  * what's happening on __real time__

This model confines much of the information in the devices.

I analysed this model from different perspectives.

To analyse the networking properties of the solution proposed, we must note that both spaces are accessed through their APIs.

---

# Networking properties
.subtitle[
##  Space model
]

<img alt="TSC is resource oriented and matches with HTTP verbs" src="img/transpas/networking_properties01.png" style="width: 100%;" />

???

Both APIs are based on the space-based computing primitives, which are compatible with (most of) the REST principles:

* It is resource oriented. It has the following types of resources: spaces

---

# Networking properties
.subtitle[
##  Space model
]

<img alt="TSC is resource oriented and matches with HTTP verbs" src="img/transpas/networking_properties02.png" style="width: 100%;" />

???

which contain RDF Graphs

---

# Networking properties
.subtitle[
##  Space model
]

<img alt="TSC is resource oriented and matches with HTTP verbs" src="img/transpas/networking_properties03.png" style="width: 100%;" />

???

which contain RDF triples.

The triples are the most basic information unit in Triple Space Computing.

---

# Networking properties
.subtitle[
##  Space model
]

<img alt="TSC is resource oriented and matches with HTTP verbs" src="img/transpas/networking_properties04.png" style="width: 100%;" />

???

* HTTP verbs can be directly mapped to TSC primitives.
* We use other HTTP features: status codes, content negotiation, etc.

---

# Networking properties
.subtitle[
##  Space model
]

<img alt="The API is not hypermedia-driven" src="img/transpas/networking_properties05.png" style="width: 100%;" />

???

Unfortunately, the APIs are not hypermedia-driven, that is they do not follow the HATEOAS REST principle.

In short, this principle means that the client should not __know__ anything apart from an __URL__ to use an API.
It should drive the interaction __selecting the new application states__ from the web hypermedia content provided by the server at each step.

Although, the API is actually hypermedia-driven for humans, it is not for machines.
This has left as future work.

---

# Networking properties
.subtitle[
##  Space model
]

REST-like APIs

* Scalability
* Simplicity
* UP performance
* Efficiency
* Evolvability

???

Anyway, accessing to the spaces through a REST-like API provides the following features to our model:

* Scalability (4+)
* Simplicity (3+-)
* UP performance, efficiency & evolvability (2+)
* and others [avoid enumeration]
 * Portability, extensibility, configurability, reusability & reliability (+)
 * Visibility (+-)
 * Net performance (-)

And it also comes with some drawbacks:

* Less simplicity, reusability & visibility than pure REST APIs (hypermedia-driven)
* Mechanisms such as subscriptions and transactions go against the statelessness

---

# Coordination properties
.subtitle[
##  Space model
]

<img alt="Space and time" src="img/uncoupling.svg" style="width:60%; margin-top: 2em; display: block; margin-left: 12em; margin-right: auto"/>
<div style="margin-top: 1em;">
 <span style="margin-left: 12em;">Space uncoupling</span>
 <span style="float:right;">Time uncoupling</span>
</div>

???

But, having a part of the model which is based on the web also affects uncoupling.

[Move the explanation of uncoupling here?]
<!-- Not yet because I'm unsure whether these slides will be kept -->

--

<div>
 <span style="float:left;">Coordination space</span>
 <span style="width: 20em; float:right;">
     <span style="margin-left: 25%; color: #4db849; font-size: 2em; vertical-align: middle;">&#10004;</span>
     <span style="margin-left: 40%; color: #4db849; font-size: 2em; vertical-align: middle;">&#10004;</span>
  </span>
</div>

???

Obviously, the coordination space corresponds with the clasical model and therefore has both uncoupling levels.

---

# Coordination properties
.subtitle[
##  Space model
]

<img alt="Space and time" src="img/uncoupling.svg" style="width:60%; margin-top: 2em; display: block; margin-left: 12em; margin-right: auto"/>
<div style="margin-top: 1em;">
 <span style="margin-left: 12em;">Space uncoupling</span>
 <span style="float:right;">Time uncoupling</span>
</div>

<div>
 <span style="float:left; color: #cccccc;">Coordination space</span>
 <span style="width: 20em; float:right;">
     <span style="margin-left: 25%; color: #adb8ac; font-size: 2em; vertical-align: middle;">&#10004;</span>
     <span style="margin-left: 40%; color: #adb8ac; font-size: 2em; vertical-align: middle;">&#10004;</span>
  </span>
</div>

<div style="clear:both;">
  <span style="float:left;">Outer space</span>
  <span style="width: 20em; float:right;">
      <span style="margin-left: 25%; color: #4db849; font-size: 2em; vertical-align: middle;">&#10004;</span>
???

In the _outer space_, programmers are forced by space-based primitives not to care about data too.

--
      <span style="margin-left: 40%; color: #e53f39; font-size: 1.5em; vertical-align: middle;">&#10060;</span>
  </span>
</div>

???

However, regarding _time uncoupling_, since each provider holds its content, this is only accessible when the provider is available.

Some possible solutions to avoid this uncoupling would be: to move contents to other nodes or to replicate contents.
However, this will come at the cost of more complexity and networking activity.
<!-- * __Move contents__ to other nodes
  * how to distinguish the reliable ones?
  * the measures would be moved away from where they are generated
   * what if the other node lefts the space but the provider is available?
* __Replicate__ contents
  * more networking
  * maintaining the data consistency is not easy with unreliable nodes
-->

Therefore, I kept it this way, with an time coupled outer-space, when I identified (realized) that we used the space for different purposes:

 1. Search for information
 1. Coordinate through the space

Time uncoupling is particularly important for coordination, but not so much to search (in real time).

---

# Properties for UbiComp
.subtitle[
##  Space model
]

<img alt="Space and time" src="img/transpas/ubicomp_properties01.png" class="center" style="width:90%;"/>

???

Finally, we can see how the properties commented before interrelate with desirable properties in UbiComp.

Particularly, we can see two conflictive interrelations:

---

# Properties for UbiComp
.subtitle[
##  Space model
]

<img alt="Space and time" src="img/transpas/ubicomp_properties02.png" class="center" style="width:90%;"/>

???

Firstly, the web has a low networking perfomance.

To reduce or mitigate it, we can redesign the API or just adopt more lightweight protocols (e.g., CoAP which mimics many of HTTP's properties).

---

# Properties for UbiComp
.subtitle[
##  Space model
]

<img alt="Space and time" src="img/transpas/ubicomp_properties03.png" class="center" style="width:90%;"/>

???

Secondly, the semantic web negatively affects computation overload and energy autonomy.

For this purpose, we have specifically designed a search architecture.

---

class: center, middle

# Energy-aware Search Architecture <!-- TODO call it in other way??? -->

.citations[

* Aitor Gómez-Goiri, Iñigo Goiri, and Diego López-de-Ipiña.
Energy-aware architecture for information search in the semantic web of things.
[International Journal of Web and Grid Services](http://www.inderscience.com/jhome.php?jcode=ijwgs), [Vol. 10, No. 2/3](http://www.inderscience.com/info/inarticle.php?artid=60252), pp. 192–217, 2014.
* Aitor Gómez-Goiri and Diego López-de-Ipiña.
Assessing data dissemination strategies within triple spaces on the web of things.
In 2012 Sixth International Conference on Innovative Mobile and Internet Services in Ubiquitous Computing (IMIS), pages 763 –769, July 2012.
]

???

And this is precisely the second goal of my dissertation.

---

# Problem: in the context of this PhD <!-- Or specific -->
.subtitle[
## Energy-aware search architecture
]

How to search in the _outer space_?

<img alt="Proposed dual model" src="img/new_model.svg" style="width: 100%;" />

???

How can we search in the _outer space_?

Remember that the "asteroids" from the right-hand side are independent small web providers.

Or generalizing it...

---

# Problem: a generalization
.subtitle[
## Energy-aware search architecture
]

<img alt="XXX" src="img/transpas/search_motivation01.png" class="center" style="width:100%;"/>

???

How to search in a semantic web provided by limited devices?

(and remember my driving motivation: to promote the direct communication between)

---

# Problem: a generalization
.subtitle[
## Energy-aware search architecture
]

<img alt="XXX" src="img/transpas/search_motivation02.png" class="center" style="width:100%;"/>
<!-- cacharros preguntandose entre sí -->

???

Devices need to communicate with each other directly, but this cannot be done at any price.

For instance, a broadcasting-based solution will generate a high computation and networking activity.

---

# Energy consumption: an example
.subtitle[
##  Energy-aware search architecture
]

<img alt="FoxG20 used to measure energy" src="img/transpas/foxg20.jpg" style="width: 80%;" class="center" />

<!-- TODO put details about this platform
TODO foto de la fuente de alimentación programable -->

???

To find out how this computing and networking activities could affect an embedded platform,
I checked their effects in a FoxG20 embedded device.

---

# Energy consumption: an example
.subtitle[
##  Energy-aware search architecture
]

<img alt="Energy consumption for each type of activity" src="img/energy_consumption.svg" style="width: 80%;" class="center" />

???

In periods when it reasons or attends HTTP requests, it consumes approximately 20% more energy.
In other platforms, similar energy wastes can be presumed.

But beyond concrete energy consumptions, what this __chart transmits__ is that since computation and networking result in significant higher energy consumption,
we need to find a strategy which efficiently manages both aspects.

---

# Roles
.subtitle[
## Energy-aware search architecture
]

<img alt="Roles for the search-architecture: White Page" src="img/transpas/search_roles01.png" style="width: 100%;" class="center" />

???

What __I conceived__ is an architecture which uses "search facilitators" to help nodes to __improve__ their search process.

This "search facilitator", called White Page from now on, is chosen dynamically between all the nodes in a space and can change over the time.

---

# Roles
.subtitle[
## Energy-aware search architecture
]

<img alt="Roles for the search architecture: Providers" src="img/transpas/search_roles02.png" style="width: 100%;" class="center" />

???
 
Apart from the White Page role, a node can have two other roles:

 * _Providers_...

---

# Roles
.subtitle[
## Energy-aware search architecture
]

<img alt="Roles for the search architecture: Providers hold contents" src="img/transpas/search_roles03.png" style="width: 100%;" class="center" />

???
 
...which carry their own semantic information

---

# Roles
.subtitle[
## Energy-aware search architecture
]

<img alt="Roles for the search architecture: Consumers" src="img/transpas/search_roles04.png" style="width: 100%;" class="center" />

???

and _Consumers_...

---

# Roles
.subtitle[
## Energy-aware search architecture
]

<img alt="Roles for the search architecture: Consumers" src="img/transpas/search_roles05.png" style="width: 100%;" class="center" />

???

...which directly request or query providers to obtain fresh data.

---

# Roles
.subtitle[
## Energy-aware search architecture
]
<img alt="Devices have different roles at each moment" src="img/transpas/devices_have_roles.png" style="width: 100%;" class="center" />

???

Note that from now to the evaluation, I will talk about roles rather than specific devices.

Each device can select at any time its role: provider, consumer, both or none.

The White Page is selected between all of them.
For instance, from the figure, providing the laptop is steady, it may be chosen as the new WP.

---

# Clues
.subtitle[
## Energy-aware search architecture
]
<img alt="XXX" src="img/transpas/search_proposal01.png" class="center" style="width:100%;"/>

???

So, to facilitate this search, I propose to summarize the information through a piece of information called _clue_.

Note that the system is based in an assumption:
_clues do not change frequently since they represent the type of information the nodes host rather than the specific data which is constantly generated_

_Providers_ summarize this knowledge into pieces of information called _clues_ (processing it)

---

# Clues
.subtitle[
## Energy-aware search architecture
]
<img alt="XXX" src="img/transpas/search_proposal02.png" class="center" style="width:100%;"/>

???


Providers send a clue to WP in any of the following situations:
 1. when a clue is updated
 2. before its lifetime expires
 3. whenever there is a new WP in the Space with a lower setup version than the one in the Provider
 
The White Page stores clues in what it is called an _aggregated clue_.
This _aggregated clue_ is versioned (in the figure, it has the _i-1_ version).

---

# Clues
.subtitle[
## Energy-aware search architecture
]
<img alt="XXX" src="img/transpas/search_proposal03.png" class="center" style="width:100%;"/>

???

Once it receives the new clue, the White Page adds it to the _aggregated clue_, creating a new version (in the figure _i_).

---

# Clues
.subtitle[
## Energy-aware search architecture
]
<img alt="XXX" src="img/transpas/search_proposal04.png" class="center" style="width:100%;"/>

???

As a response to its request, the providers obtains this aggregated clue version.

The aggregated clues are the piece of informations which helps _Consumers_ searching for information efficiently.

---

# Clues
.subtitle[
## Energy-aware search architecture
]
<img alt="XXX" src="img/transpas/search_proposal05.png" class="center" style="width:100%;"/>

???

Therefore, _Consumers_ need to obtain an _aggregated clue_.

This happens in these occasions:
  1. they don't have one
  2. periodically
   * upper bound time: ensures a fresh view
   * lower bound time: not to flood the WP
   * in between, checking the average frequency when the last 10 queries have happened
   
Using this _aggregated clue_ data, their are able to independently resolve their queries.

---

# Clues
.subtitle[
## Energy-aware search architecture
]
<img alt="XXX" src="img/transpas/search_proposal06.png" class="center" style="width:100%;"/>

???

That is, they process them to decide which nodes to ask for information.

Exceptionally, as an optimization for nodes with severe computation restrictions, _Consumers_ can also the WP can answer directly which nodes it should ask for. 

---

# Clues
.subtitle[
## Energy-aware search architecture
]
<img alt="XXX" src="img/transpas/search_proposal07.png" class="center" style="width:100%;"/>

???

Finally, the consumer is now able to decide to which node address its request.

---

# Clue content
.subtitle[
## Energy-aware search architecture
]

<img alt="Semantic example and clue types" src="img/transpas/semanticExample01.png" style="width: 100%;" />

???

So, how do this clues look like?

A clue is a summary of the information hold by a provider.

This information looks as the figure shows.

The semantic web is formed by RDF triples.

They are composed by a subject, a predicate and an object.

---

# Clue content
.subtitle[
## Energy-aware search architecture
]

<img alt="Semantic example and clue types" src="img/transpas/semanticExample02.png" style="width: 100%;" />

???

As a query language, I have considered wildcard-patterns such as the ones shown at the bottom of the image.
<!-- TODO transpa backup explicando por qué no SPARQL -->


So, considering that clues need not to change frequently, I considered three alternatives:

---

# Clue content
.subtitle[
## Energy-aware search architecture
]

<img alt="Semantic example and clue types" src="img/transpas/semanticExample03.png" style="width: 100%;" />

???

* __Predicates__ which contain the relations between terms (just the significants).
 * In the example, ssn:observes and ssn:observedBy.

---

# Clue content
.subtitle[
## Energy-aware search architecture
]

<img alt="Semantic example and clue types" src="img/transpas/semanticExample04.png" style="width: 100%;" />

???

* __Prefixes__, which indicate the vocabularies used by the node to describe the knowledge provided.
 * In the example, ssn, weather, sweet and ex.
 
---

# Clue content
.subtitle[
## Energy-aware search architecture
]

<img alt="Semantic example and clue types" src="img/transpas/semanticExample05.png" style="width: 100%;" />

???

* __Classes__ stored which detail which types of terms a node provides.
 * In the example, ssn:Sensor and weather:RainfallObservation.

---

# Discovery
.subtitle[
## Energy-aware search architecture
]

Using a __discovery mechanism__ each node shares:

1. the __Spaces__ it belongs to,
2. whether it is __White Page__ (+ its setup version)
3. information for the White Page __selection__ process

???

To run our proposal, we require a __discovery mechanism__ able to

1. get the Spaces that a particular node belongs to,
2. identify the WP and its setup version, and
3. provide additional information about nodes to decide which one can be the next WP.

I tested the impact of the discovery mechanism using mDNS and DNS-SD.
However, the specific mechanism used is transversal to the architecture.

---

# White page selection
.subtitle[
## Energy-aware search architecture
]
<img alt="XXX" src="img/transpas/wp_selection01.png" class="center" style="width:100%;"/>

???

The selection process can start

1. when no WP is available (in this case, the first node to realize its absence starts this process) or

---

# White page selection
.subtitle[
## Energy-aware search architecture
]
<img alt="XXX" src="img/transpas/wp_selection02.png" class="center" style="width:100%;"/>

???

2. when the current WP gets a worse score than other nodes (in this case, it's the current WP who checks this)

---

# White page selection
.subtitle[
## Energy-aware search architecture
]
<img alt="XXX" src="img/transpas/wp_selection03.png" class="center" style="width:100%;"/>

???

And how does the selection work?

The "WP selector" ranks the nodes according to the information provided by their discovery mechanism.

---

# White page selection
.subtitle[
## Energy-aware search architecture
]
<img alt="XXX" src="img/transpas/wp_selection04.png" class="center" style="width:100%;"/>

???

approximate time since the device joined the Space (to estimate its reliability),

---

# White page selection
.subtitle[
## Energy-aware search architecture
]
<img alt="XXX" src="img/transpas/wp_selection05.png" class="center" style="width:100%;"/>

???

and its memory,

---

# White page selection
.subtitle[
## Energy-aware search architecture
]
<img alt="XXX" src="img/transpas/wp_selection06.png" class="center" style="width:100%;"/>

???

* storage capacity, and

---

# White page selection
.subtitle[
## Energy-aware search architecture
]
<img alt="XXX" src="img/transpas/wp_selection07.png" class="center" style="width:100%;"/>

???

* battery level.

The goal of this ranking is to move the additional load needed to maintain the architecture to the most __powerful and stable__ device in the space.

---

<!-- TODO Slide recap: why is it energy aware and how does it help on the computation? -->

# Experimental environment: simulation inputs
.subtitle[
## Energy-aware search architecture
]

<img alt="Real time measures" src="img/transpas/time_measures.png" style="width: 100%;" />
[I will replace this table, with a chart, the photos of the real devices used and their specs]

???

To test all this architecture, I carried out several simulations.

To parametrize them, I used the following response times as inputs.
They have been measured in the real platforms shown and they affect the performance of the solution and indirectly how much energy is consumed.

---

# Experimental environment: simulation inputs
.subtitle[
## Energy-aware search architecture
]

<img alt="Sample templates" src="img/transpas/evaluation_templates.png" style="width: 100%;" />
[Apart from this, I will enumerate the sources of my datasets to show they authenticity]

???

For the data used in the simulation, I extracted them from real datasets describing sensing stations and their measures.

The templates used are the ones shown in the table.
They consider queries from different nature.

---

# Compared strategies
.subtitle[
## Energy-aware search architecture
]

[Schema showing how negative broadcasting works]

<!-- FIXME Añadir una transpa justificativa de por qué no he implementado otras del estado del arte!
Poner las que luego ví que existían basadas en cachear, por lo cual medio cubro esto :-P
Otras o muy complejas de implementar, o no ponían el código.
-->

???

As a baseline for the comparison, I used the rawest strategy: negative broadcasting.
In this strategy, a node propagates its query to the rest of the nodes it knows about.

As an optimization, a node can memorize which nodes successfully answer the same query in the past.
That is, they can implement caching.

---

# Evaluation: Network activity
.subtitle[
## Energy-aware search architecture
]

<img alt="Requests generated using different strategies" src="img/requests_by_strategies.svg" style="width: 90%;" />

???

In the figure we show the results of performing 1.000 queries during one hour for 1 or 100 consumers using each of the strategies explained.

Obviously my solution is better than NB.
Comparing it to caching, it depends on the # of consumer and the # of queries.

For the same number of queries, the more consumers there are, the closer to NB caching behaves.
The figure shows that with 100 consumers, the caching strategy is in between NB and our solution.

Caching with just one consumer is better than our solution in most of the cases.
However, as the as the network size increases it gets very close to our solution.

In our solution we can see that an increase in the number of consumers does not increase the numbers of requests too much.
In fact, the difference between this two cases is found in the additional management tasks.
We can also check the 

<!-- NOTA este caso es uno en el que las clues permiten discriminar muy bien, caching es mejor para preguntas que se repiten mucho,
lo nuestro tira con "tipos de pregunta" semejantes -->

---

# Evaluation: Network activity (by device type)
.subtitle[
## Energy-aware search architecture
]

<img alt="Energy consumption for each class" src="img/activity_measures.svg" style="width: 100%; margin-top: 10%;" />

???

In this chart, we analyse the networking activity generated in each node (on average).

The experiment consists of 300 nodes joined to a Space running on:
 * 1 server,
 * 30 galaxy tabs,
 * 75 FoxG20 and
 * 194 Digi’s XBee sensors


On the left hand side we can see how each device __reduces its activity__ considerably.

On the right hand side, we see two desired effects:

 * the limited devices face less requests and consequently reduce their activity
 * the additional tasks generated by the solution are moved to the more powerful ones

---

# Evaluation: Network activity (high dynamism)
.subtitle[
## Energy-aware search architecture
]

<img alt="XXX" src="img/transpas/evaluation_dynamic.png" style="width: 100%; margin-top: 10%;" />

???

Using the same devices as in the previous simulation, this evaluation shows what happens when we have a very dynamic scenario where nodes frequently come and go.
Specifically, it simulates nodes joining and leaving the Space at different intervals: 30 seconds, 1 minute, 5, 10, 20, 30 and 45 minutes.
We also added an scenario with no drops as a baseline.
Note that we represent this scenario by configuring the drop-interval with a greater value than the simulation time.

Furthermore, the evaluation tests the most harmful situation: the node leaving the Space abruptly is always the WP. 

In the right hand side, we see how the solution presented does not present a substantial overhead comparing to NB.

In the left hand side, we see that for a frequent drop-interval, providers are forced to send their individual clues to many new WPs.
However, when the aggregated clues have enough time to be propagated to most of the consumers (in this case at 5 minutes drop interval),
the new WP can be initiated from a previous aggregated clue version.
This avoids the situation when most of the providers re-send their clues over and over.

---

class: center, middle

# Actuation

???

The third goal of my dissertation was to explore how to actuate through space-based computing.

Specifically, the idea I present here is currently in its early stages and still has to be fully developed.
However, I find it interesting as it covers the actuation in space-based computing from a completely novel perspective.

---

# Patterns for Tuple Spaces
.subtitle[
## Actuation
]

???

To solve this question I first examined the common actuation patterns over Tuple Spaces.

For sake of brevity, I will present just two of them.

The first one is the __replicated-worker pattern__.

In this pattern, there is a master process and many worker processes able to compute the same task.

1. The master takes a problem, divides it into smaller tasks, and
2. writes these tasks into the space.
3. Any available worker takes a task,
4. processes it,
5. and writes the result back into the space.

When all the workers have written their results,

1. the master takes these results and
2. combines them into a meaningful merged solution

This pattern is scalable and naturally balances the load on the space.

---

# Patterns for Tuple Spaces
.subtitle[
## Actuation
]

???

The second pattern in the __specialist pattern__.

It can be as a variation of the previous one.
The different is that in this pattern each worker is specialized and performs a particular task.

---

# Patterns for Tuple Spaces in UbiComp
.subtitle[
## Actuation
]

???

We can translate the previous patterns to the UbiComp usage examples.

For instance, a node may write a "task to turn the fan on" in the space.

A smart-fan which belongs to the same space, will then take the task, process it and activate the blades.

Then, it may write a result in the space (e.g., with information about when it was turned on) that the "activator node" will read.

---

# Limitations
.subtitle[
## Actuation
]

???

This approach has been widely applied in the literature.
Particularly, this idea evolved into service-oriented engines.
The task-types where described through services and task through _service invocations_.

In fact, in a pre-PhD paper, I also explored this approach.
However, the more about I read about WoT, the more I liked its simple actuation mechanism.

---

# HTTP API
.subtitle[
## Actuation
]

HTTP POST /fan/blades/01

Content

true


???

For example, for the fan, we could simply make a HTTP POST request to the smart-fan at the URL shown.

However, remember that this per-se is not REST.

---

# HTTP API
.subtitle[
## Actuation
]

[grafo explicando como llegar al siguiente paso]

/fan -> /fan/blades/01
 -> /fan/blades

???

To achieve the hypermedia-drivenness, the application has to describe the state transitions the client can select through hypermedia.

Doing this in a way that the client can be a machine is currently a hot research topic.

Some solutions propose to use the semantic web to describe this applications and state transitions.

Personally, I have experimented with the one which, in my honest opinion, combines better the flexibility and simple design.
It is called RESTdesc.

---

# RESTdesc
.subtitle[
## Actuation
]

[rule example remarking its different parts]

???

RESTdesc describes HTTP methods using rules expressed in the Notation 3 (or N3) language.

A rule’s premise expresses the requirements to make an state transition.

A rule’s conclusion expresses both the REST call that needs to be made and the description of the invocation results.

---

# RESTdesc
.subtitle[
## Actuation
]

[previous rule and the URL where we can get it]

[el esquemita de un dispositivo obteniendo eso mismo: un fichero con una premisa y conclusión]

???

These descriptions can be obtained through different mechanisms.

We will assume that they are provided in the same resources which it describes using the HTTP OPTIONS verb.

---

# RESTdesc
.subtitle[
## Actuation
]

[el fichero N3]

[otro fichero con una F de final en la conclusión]

[background knowledge]

[paso a paso de lo que pasa, como se procesa, se obtiene un plan, que tiene pasos, que tienen HTTP requests]

???

So when a client has crawled an API collecting several of these descriptions, what can we do with them?

This client needs to have also:

* a goal: other rule which expresses the ending state it wants to reach
* background knowledge expressed with semantics

With these 3 pieces of information, it can use a reasoner (e.g. EYE reasoner) to make a tentative plan.

This plan indicates different paths to reach the desired goal (or final state).
Let us assume that there is only one path or no path.

This path will contain different steps composed by the rules which need to be invoked to obtain a plan.
And since this rules are composed by the HTTP requests, we just have to check that we can invoke them.

---

# Motivation
.subtitle[
## Actuation
]

???

In short, RESTdesc helps machines learning how to use an API autonomously.
That is, becomes them hypermedia-driven.

The main advantage of an hypermedia-driven API is that it can its _shape_ over the time and the applications automatically consuming it will not need to be reconfigured or redeveloped.

So, considering the current prevalence of REST-like APIs, this additional feature will open a new world of possibilities to web apps.
Translating it to the WoT field, it will allow to act using actuators unknown beforehand.

---

# Comparison
.subtitle[
## Actuation
]
<img alt="XXX" src="img/transpas/actuation_comparison.png" style="width: 100%; margin-top: 10%;" />

???

However, both mechanisms are quite distinct in nature.
One promotes the direct communication style, while the other promotes an indirect uncoupled style.

We can also see in the table how each of them require additional features: <!-- TODO subrayar en la tabla -->

* A subscription mechanism in the case of space-based computing.
 It helps nodes to be aware of what is written into the space without constantly polling it.
* A reasoner to create a execution plan


So I made myself a question, could space-based computing take advantage of these existing REST-based actuators?
Furthermore, could this reuse be made in a seamless way for nodes already following each of techniques?

---

# Driving scenario
.subtitle[
## Actuation
]

[dibujito del escenario]

???

As a first step to answer this question, I planned a baseline scenario and implemented it using both mechanisms.

The scenario is the "helloworld" of the scenarios: turning on and off a light.
However, it helps to understand both actuation mechanisms and test the interoperation ideas.

---

# Comparison
.subtitle[
## Actuation
]
<img alt="XXX" src="img/transpas/requests_by_techniques.svg" style="width: 100%; margin-top: 5%;" />

???

After implementing both scenarios, I tested how the variation in the number of providers (e.g., actuators) affected these techniques.

First, we can see that as the amount of actuators increases, both techniques generate more requests.
The slope will vary depending on the design (and implementation) of each solution.
In any case, the figure shows that none of the techniques behave in a scalable manner.

In the case of space-based actuation, the variation corresponds to the subscription request of each actuator and two additional writings it does. <!-- FIXME comprobar que es así -->

In the case of REST-based actuation the crawler needs to obtain 5 different rules for each actuator.

---

# Comparison
.subtitle[
## Actuation
]

<!-- TODO put the Raspberry Pi and its characteristics -->

<img alt="XXX" src="img/transpas/performance_by_techniques.svg" style="width: 100%; margin-top: 10%;" />

???

In this second chart, we see that the amount of actuators affects more severely to REST-based actuation.
This is due mainly to the to the reasoning process which takes place in the node which generates the plan.

[causes]


In Space-based actuation, all the participants must be aware of what is writ-
ten into the space to react (i.e., they are proactive). Both consumers and pro-
viders read and write from the space, 

However, in space-based actuation each actuator subscribes to specific changes.
Thanks to this specificity, they are only affected by the contents they are interested in, generating . On the contrary, the Space will be involved in any net-
working activity. Therefore, although it depends on the number of providers
and consumers’ interactions, the networking activity will presumably be high
for the node hosting the Space.

---

# Comparison
.subtitle[
## Actuation
]

[tabla comparación]

???

From the results and after analysing the characteristics of both techniques, we came out to the following table.
It summarizes the strengths and weaknesses of both techniques.

In the XXX, we can see that...

---

# Interoperation
.subtitle[
## Actuation
]

[schema which takes REST-based provider and space-based change activation node <-- name this somehow previously]
[space with additional processing]

???

With these considerations in mind, I propose a solution which does not affect any of the actuators of nodes which generate changes from the previous scenario.

In this solution, all the changes are performed in the space.

---

# Interoperation: execution
.subtitle[
## Actuation
]

[las tuercas, se convierten en una ejecución donde se ponen las equivalencias que hace]

???

• It uses the Node B’s subscription to the task result as a goal for the reason-
ing. In our implementation, this correspondence needs a minimal map-
ping between N3QL [144] and SPARQL [162]. The reason why we use
both languages are the underlying frameworks: EYE [149] and RDFLib
[133].
• The agent uses all the content written into the space as additional know-
ledge for the reasoning process. This is feasible because the agent resides
in the same machine as the space. Otherwise, acquiring this knowledge
through the network would be too consuming both in bandwidth and in
time.

---

# Discussion
.subtitle[
## Actuation
]

<!-- TODO mirar a ver si sé explicar los otros problemas facilmente -->

* If there are two or more paths to reach a goal, how can we discern which
one to follow? This problem is specific to the REST actuation.
* How does the middleware deal with the coexistence of both mechanisms?
When both methods can be applied, which one is triggered? Will one of
them prevail over the second?

???

---

class: center, middle

# Conclusion

???

To conclude, let me give some views on the areas I experimented in during my dissertation and tell you my contributions in this aspect.

---

# Conclusions

* __Limited devices are not just dumb devices__
 * Managing semantic content in limited devices is still challenging
* __Do we really need the Semantic Web?__
 * We sometimes look down on interoperability
 * Sometimes the lack of adequate tools make too complex for a human to annotate contents
* __Will true-REST-architectures ever prevail?__

???

* This dissertation has addressed this problem from a novel perspective: give responsibilities to limited devices
 * Managing semantic content in limited devices is still challenging
 * However, there are many interesting parallel works on reasoning, compressing the contents, etc.
* We sometimes look down on interoperability: both in the academia and in the industry.
 * In the academia, due to the prototyping nature of most of our applications
 * In the industry, due to a lack of openess and real need of interoperate with big amount of data.
 * Furthermore, interoperability benefits are usually perceived in the mid/long term.
 * However, this is changing too with the _Linked Data_ initiative.
* Will true-REST-architectures ever prevail?
 * Some interesting works are leveraging this challenge
 * I have experimented for the first time how one of this proposals could be used from the space-based perspective.

---

# Contributions

* Space-model which integrates with the web-world
* A searching mechanism for WoT
 * Promotes end-to-end HTTP requests between constrained devices
 * Balances the management load considering devices' computing and energy capacities
 * Structures the nodes in different dynamic roles with different responsibilities
* Analysis of how to interoperate with existing REST-based actuators from space-based computing
* [Enumeration of the papers, etc.] <!-- Enumerar la larga que la tengo? -->

???

* End-to-end: they do not need an intermediary to search (i.e., to select the appropriate providers to request).

---

# Technical contributions

* __Otsopack__
* Parametrizable __simulation environment__
* Implementation of the same __basic actuation scenario__ to compare different actuation mechanisms
 
In parallel...

* Lightweight __user access control__ for limited devices
* Use of Otsopack in a number of __different domains__
 * Homes, hospitals and residences, supermarkets or hotels.

???

Otsopack is a middleware which follows some of the ideas presented about web-based semantic space-based computing.

---

class: middle, questionslide

# Questions?
Aitor Gómez Goiri .breakline[ aitor.gomez (at) [deusto (dot) es](http://www.deusto.es)]


???

With this I conclude my presentation and I am ready to answer the questions and comments you make issue regarding this dissertation.

Thank you very much for listening.

---

class: center, middle

All rights of images are reserved by the <br />
__original owners__*, the rest of the content is licensed <br />
under a __[Creative Commons by-sa 3.0](http://creativecommons.org/licenses/by-sa/3.0/)__ license.

<div style="margin-top:3em"/>

![Creative commons by-sa 3.0 license logo](img/CC-logo.svg)

<div style="margin-top:3em"/>

\* [leogg](http://openclipart.org/detail/89209/),
[finchweb](http://openclipart.org/detail/170018/),
[rduris](http://openclipart.org/detail/167948/),
[williamtheaker](http://openclipart.org/detail/178310/),
[cibo00](http://openclipart.org/detail/14056/),
[liftarn](http://openclipart.org/detail/181651/),
[jiangyi_99](http://openclipart.org/detail/183056/),
[mazeo](http://openclipart.org/detail/87055/) and
[Justin Ternet](http://openclipart.org/detail/182928/).


---

class: center, middle

# Backup slides

<!-- TODO poner todas las figuras y evaluaciones! -->

---

# The Semantic Web and limited devices

???

Some <!-- Our early attempts with Arduino were unsuccessful-->

However, with current advances in:

 * semantic reasoners for this type of environments (mencionar al tio que hizo un razonador adaptado)
 * lightweight semantic formats
 * lightweight web protocols
 * mobile and embedded devices' the processing capacity
 * [autonomy of the batteries](http://energi.us/liberacion-patentes-tesla/) or
 * energy harvesting...

More and more devices will be able to manage semantics.
 <!--
 TODO
 Preparar una transpa de backup por si preguntan cómo de viable es.
 Ideas:
   * Many of the current devices are able to manage their info
   * Gráfico con pruebas que hicimos en su día:
    * Even if it is more verbosed
    * Some of them can reason and expand this information.
    * Others may need to rely in third machines.
     * Out of the scope
    * Anyway, we might be anticipating a trend.
 -->
---

# Space model: baseline

Triple Space Computing (TSC)

 * Spaces identified by URIs
 * Tuples == RDF Triples & RDF Graphs
 * Templates = triple patterns

<div style="margin-top:2em;" />

![Resources in TSC](img/tsc_resources.svg)

???

Uses elements from the SW

---

Problem: semantic computation (podemos poner hasta graficos de cosas que hayamos hecho)

---

# Hypothesis: some definitions

  * Heterogeneity: Fully-fledged computers and resource constrained devices (e.g., mobile and embedded devices) must coexist in these environments.
  * Autonomy: Devices must not depend on others to consume or provide data on their behalf.
  However, they might be aided by other devices to complete some related tasks (e.g., search the appropriate nodes to request).
  * Uncoupling: The communication must be data-driven.
  From the user perspective devices do not directly refer to each other.
  Additionally, the provider and the consumer should not coexist in time.
  However, note that since this sub-aspect contradicts the autonomy principle, their selection might be left to the user.
  * Interoperability: Devices must be able to exchange information with other systems and to use that information.

---

class: center, middle

# Additional Evaluation

---

# Evaluation: Network activity (by role)

<img alt="Requests by role" src="img/transpas/evaluation_requests.png" style="width: 100%; margin-top: 10%;" />

???

In the following chart we show the type of communication for an scenario with 100 consumers and different network sizes.

It shows that most of the requests are from consumers to providers.

Therefore, maintaining the architecture does not creates much overhead and it does not increase much with the number of consumers.
  
    </textarea>
    <!--<script src="http://gnab.github.io/remark/downloads/remark-0.5.9.min.js" type="text/javascript">-->
    <script src="remark-0.5.9.min.js" type="text/javascript">
    </script>
    <!-- Substitute with remark-latest.min.js -->
    <script type="text/javascript">
      var slideshow = remark.create();
    </script>
  </body>
</html>
